<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>音声感情分析アプリ - 声から感情を読み取る</title>
    <style>
        * { box-sizing: border-box; margin: 0; padding: 0; }
        body { 
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            color: white;
        }
        .container {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            padding: 2rem;
            border-radius: 20px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
            text-align: center;
            max-width: 500px;
            width: 90%;
        }
        h1 {
            font-size: 2.5rem;
            margin-bottom: 2rem;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
        }
        .audio-visualizer {
            width: 100%;
            height: 200px;
            background: rgba(0, 0, 0, 0.3);
            border-radius: 10px;
            margin: 1rem 0;
            position: relative;
            overflow: hidden;
        }
        canvas {
            width: 100%;
            height: 100%;
        }
        .emotion-result {
            font-size: 1.5rem;
            margin: 1rem 0;
            padding: 1rem;
            background: rgba(255, 255, 255, 0.2);
            border-radius: 10px;
            min-height: 60px;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        .emotion-emoji {
            font-size: 3rem;
            margin: 0 1rem;
        }
        button {
            background: white;
            color: #667eea;
            border: none;
            padding: 1rem 2rem;
            font-size: 1.2rem;
            border-radius: 50px;
            cursor: pointer;
            transition: all 0.3s;
            margin: 0.5rem;
            font-weight: bold;
        }
        button:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.3);
        }
        button:disabled {
            opacity: 0.6;
            cursor: not-allowed;
        }
        .recording {
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(255, 255, 255, 0.7); }
            70% { box-shadow: 0 0 0 10px rgba(255, 255, 255, 0); }
            100% { box-shadow: 0 0 0 0 rgba(255, 255, 255, 0); }
        }
        .emotion-chart {
            margin-top: 2rem;
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(100px, 1fr));
            gap: 1rem;
        }
        .emotion-bar {
            background: rgba(255, 255, 255, 0.2);
            border-radius: 10px;
            padding: 0.5rem;
            position: relative;
        }
        .emotion-bar-fill {
            background: linear-gradient(90deg, #f093fb 0%, #f5576c 100%);
            height: 100px;
            border-radius: 5px;
            transition: height 0.5s ease;
            position: absolute;
            bottom: 30px;
            left: 10px;
            right: 10px;
        }
        .emotion-label {
            position: absolute;
            bottom: 5px;
            left: 0;
            right: 0;
            font-size: 0.9rem;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>🎤 音声感情分析</h1>
        
        <div class="audio-visualizer">
            <canvas id="visualizer"></canvas>
        </div>
        
        <div class="emotion-result" id="emotionResult">
            <span>マイクボタンを押して話してください</span>
        </div>
        
        <button id="recordBtn" onclick="toggleRecording()">
            🎙️ 録音開始
        </button>
        
        <div class="emotion-chart" id="emotionChart" style="display: none;">
            <div class="emotion-bar">
                <div class="emotion-bar-fill" id="happyBar" style="height: 0%"></div>
                <div class="emotion-label">😊 喜び</div>
            </div>
            <div class="emotion-bar">
                <div class="emotion-bar-fill" id="sadBar" style="height: 0%"></div>
                <div class="emotion-label">😢 悲しみ</div>
            </div>
            <div class="emotion-bar">
                <div class="emotion-bar-fill" id="angryBar" style="height: 0%"></div>
                <div class="emotion-label">😠 怒り</div>
            </div>
            <div class="emotion-bar">
                <div class="emotion-bar-fill" id="surpriseBar" style="height: 0%"></div>
                <div class="emotion-label">😮 驚き</div>
            </div>
            <div class="emotion-bar">
                <div class="emotion-bar-fill" id="calmBar" style="height: 0%"></div>
                <div class="emotion-label">😌 平静</div>
            </div>
        </div>
    </div>

    <script>
        let isRecording = false;
        let mediaRecorder;
        let audioChunks = [];
        let audioContext;
        let analyser;
        let microphone;
        let javascriptNode;
        
        const canvas = document.getElementById('visualizer');
        const canvasContext = canvas.getContext('2d');
        canvas.width = canvas.offsetWidth;
        canvas.height = canvas.offsetHeight;

        async function toggleRecording() {
            if (!isRecording) {
                startRecording();
            } else {
                stopRecording();
            }
        }

        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                // Audio visualizer setup
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                microphone = audioContext.createMediaStreamSource(stream);
                javascriptNode = audioContext.createScriptProcessor(2048, 1, 1);
                
                analyser.smoothingTimeConstant = 0.8;
                analyser.fftSize = 1024;
                
                microphone.connect(analyser);
                analyser.connect(javascriptNode);
                javascriptNode.connect(audioContext.destination);
                
                javascriptNode.onaudioprocess = function() {
                    const array = new Uint8Array(analyser.frequencyBinCount);
                    analyser.getByteFrequencyData(array);
                    drawVisualizer(array);
                }
                
                // Recording setup
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];
                
                mediaRecorder.ondataavailable = event => {
                    audioChunks.push(event.data);
                };
                
                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    analyzeEmotion(audioBlob);
                };
                
                mediaRecorder.start();
                isRecording = true;
                
                document.getElementById('recordBtn').textContent = '⏹️ 録音停止';
                document.getElementById('recordBtn').classList.add('recording');
                document.getElementById('emotionResult').innerHTML = '<span>🎤 録音中...</span>';
                
            } catch (err) {
                console.error('マイクアクセスエラー:', err);
                alert('マイクへのアクセスが許可されていません');
            }
        }

        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
                
                if (audioContext) {
                    audioContext.close();
                }
                
                isRecording = false;
                document.getElementById('recordBtn').textContent = '🎙️ 録音開始';
                document.getElementById('recordBtn').classList.remove('recording');
                
                // Clear visualizer
                canvasContext.clearRect(0, 0, canvas.width, canvas.height);
            }
        }

        function drawVisualizer(array) {
            canvasContext.clearRect(0, 0, canvas.width, canvas.height);
            
            const barWidth = (canvas.width / array.length) * 2.5;
            let barHeight;
            let x = 0;
            
            for(let i = 0; i < array.length; i++) {
                barHeight = array[i] / 2;
                
                const r = barHeight + (25 * (i/array.length));
                const g = 250 * (i/array.length);
                const b = 50;
                
                canvasContext.fillStyle = `rgb(${r},${g},${b})`;
                canvasContext.fillRect(x, canvas.height - barHeight, barWidth, barHeight);
                
                x += barWidth + 1;
            }
        }

        async function analyzeEmotion(audioBlob) {
            document.getElementById('emotionResult').innerHTML = '<span>🔍 感情を分析中...</span>';
            
            // 実際のAPIがないため、デモ用のランダムな感情分析結果を生成
            setTimeout(() => {
                const emotions = [
                    { type: 'happy', emoji: '😊', label: '喜び', value: Math.random() * 100 },
                    { type: 'sad', emoji: '😢', label: '悲しみ', value: Math.random() * 100 },
                    { type: 'angry', emoji: '😠', label: '怒り', value: Math.random() * 100 },
                    { type: 'surprise', emoji: '😮', label: '驚き', value: Math.random() * 100 },
                    { type: 'calm', emoji: '😌', label: '平静', value: Math.random() * 100 }
                ];
                
                // 最も強い感情を見つける
                const dominantEmotion = emotions.reduce((max, emotion) => 
                    emotion.value > max.value ? emotion : max
                );
                
                // 結果を表示
                document.getElementById('emotionResult').innerHTML = 
                    `<span class="emotion-emoji">${dominantEmotion.emoji}</span>
                     <span>検出された感情: <strong>${dominantEmotion.label}</strong> (${dominantEmotion.value.toFixed(1)}%)</span>`;
                
                // 感情チャートを表示
                document.getElementById('emotionChart').style.display = 'grid';
                
                emotions.forEach(emotion => {
                    const bar = document.getElementById(`${emotion.type}Bar`);
                    bar.style.height = `${emotion.value}%`;
                });
                
                // 音声の特徴も分析（デモ用）
                const pitch = 100 + Math.random() * 200;
                const energy = Math.random() * 100;
                
                setTimeout(() => {
                    document.getElementById('emotionResult').innerHTML += 
                        `<br><small>ピッチ: ${pitch.toFixed(0)}Hz | エネルギー: ${energy.toFixed(0)}%</small>`;
                }, 500);
                
            }, 2000);
        }

        // ページロード時の初期化
        window.onload = () => {
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                alert('このブラウザは音声録音に対応していません');
                document.getElementById('recordBtn').disabled = true;
            }
        };
    </script>
</body>
</html>